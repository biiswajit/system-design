
Asynchronous process needed when you know that you have do some processing that might take a lot of time. In this case you don't want your user to wait for the processing to finish and then get a response. You might want your user to get an acknowledgement and do the processing in background and when done update in the database or something else.

## Message brokers
Message brokers are the services what provides `message queues` and a set of logic to work around the data. They are very helpful for asynchronous processing of something.
```text
API server -------> message queue ---------> worker
```
When there is a request comes for a long running process the `API server` can enqueue the request to `message queue` and later some `worker` will dequeue the request and start processing the request.

How long the message can last in the queue ?
Depends on the broker, maybe few days.

Can I do retry ?
Yes. Your worker get the data from queue process the data delete the data when process is done. If broker gets down while processing the data will still appear at the head of the queue after sometime and process again. This may cause processing over the data more than once.

Some famous message brokers are AWS SQS, RabbitMQ etc

----
## Message streams
Message streams can be helpful in "write into one and read by many" scenarios. Where producer will push the message once and many different type (consumers doing different tasks) of consumers will pull from the stream.
```text
API server ----> message stream ----> search consumer
                        |-----------> database consumer
                        |-----------> ... other consumers
```

Some famous message streams are Apache Kafka, AWS Kinesis etc

#### Basics of Apache Kafka
##### Topics
Whenever some producer pushes a message they pushes to a "topic", there can be multiple producers pushing to different topics. Consumers on the other-hand also consume message from topics. It is possible that multiple different type of consumers are pulling message from same topic.
##### Partitions
Every topics has partitions. When producer pushes a message they also specify partition id, the partition id then hashed and converted into partition index. based on the index the message will be pushed to partition. Consumers will consume message from the partitions. Max number of consumers possible per topic is equal to number of partitions in that topic. There can be different consumers consuming from same partition.
##### Commit
When a consumer consumes a message they make a commit instead of deleting the message. This commit shows where to start consuming after a restart of consumers. Since different consumers can have different commit point on same partition they can read on their own peace.

-----
## Real-time pub-sub
Instead of pulling the message from queue or stream, pub-sub publishes the message to all the subscribers. Pub-sub do not have any buffer so messages are not stored they are being published in real-time.

Redis pub-sub is a popular example.